<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html xmlns:erl="http://erlang.org" xmlns:fn="http://www.w3.org/2005/02/xpath-functions">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../otp_doc.css" type="text/css">
<title>Erlang -- Delayed Dealloc</title>
</head>
<body>
<div id="container">
<script id="js" type="text/javascript" language="JavaScript" src="../../js/flipmenu/flipmenu.js"></script><script id="js2" type="text/javascript" src="../../js/erlresolvelinks.js"></script><script language="JavaScript" type="text/javascript">
            <!--
              function getWinHeight() {
                var myHeight = 0;
                if( typeof( window.innerHeight ) == 'number' ) {
                  //Non-IE
                  myHeight = window.innerHeight;
                } else if( document.documentElement && ( document.documentElement.clientWidth ||
                                                         document.documentElement.clientHeight ) ) {
                  //IE 6+ in 'standards compliant mode'
                  myHeight = document.documentElement.clientHeight;
                } else if( document.body && ( document.body.clientWidth || document.body.clientHeight ) ) {
                  //IE 4 compatible
                  myHeight = document.body.clientHeight;
                }
                return myHeight;
              }

              function setscrollpos() {
                var objf=document.getElementById('loadscrollpos');
                 document.getElementById("leftnav").scrollTop = objf.offsetTop - getWinHeight()/2;
              }

              function addEvent(obj, evType, fn){
                if (obj.addEventListener){
                obj.addEventListener(evType, fn, true);
                return true;
              } else if (obj.attachEvent){
                var r = obj.attachEvent("on"+evType, fn);
                return r;
              } else {
                return false;
              }
             }

             addEvent(window, 'load', setscrollpos);

             //--></script><div id="leftnav"><div class="leftnav-tube">
<div class="erlang-logo-wrapper"><a href="../../index.html"><img alt="Erlang Logo" src="../../erlang-logo.png" class="erlang-logo"></a></div>
<p class="section-title">Erlang Run-Time System Application (ERTS)</p>
<p class="section-subtitle">Internal Documentation</p>
<p class="section-version">Version 11.2.2.18</p>
<ul class="panel-sections">
<li><a href="users_guide.html">User's Guide</a></li>
<li><a href="index.html">Reference Manual</a></li>
<li><a href="internal_docs.html">Internal Documentation</a></li>
<li><a href="release_notes.html">Release Notes</a></li>
<li><a href="erts.pdf">PDF</a></li>
<li><a href="../../index.html">Top</a></li>
</ul>
<ul class="expand-collapse-items">
<li><a href="javascript:openAllFlips()">Expand All</a></li>
<li><a href="javascript:closeAllFlips()">Contract All</a></li>
</ul>
<h3>Chapters</h3>
<ul class="flipMenu" imagePath="../../js/flipmenu">
<li id="no" title="Carrier Migration" expanded="false">Carrier Migration<ul>
<li><a href="CarrierMigration.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="CarrierMigration.html#introduction">Introduction</a></li>
<li title="Problem"><a href="CarrierMigration.html#problem">Problem</a></li>
<li title="Solution"><a href="CarrierMigration.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Thread Progress" expanded="false">Thread Progress<ul>
<li><a href="ThreadProgress.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="ThreadProgress.html#problems">Problems</a></li>
<li title="Functionality Used to Address These Problems"><a href="ThreadProgress.html#functionality-used-to-address-these-problems">Functionality Used to Address These Problems</a></li>
<li title="Implementation of the Thread Progress Functionality"><a href="ThreadProgress.html#implementation-of-the-thread-progress-functionality">Implementation of the Thread Progress Functionality</a></li>
</ul>
</li>
<li id="no" title="Non-Blocking Code Loading" expanded="false">Non-Blocking Code Loading<ul>
<li><a href="CodeLoading.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="CodeLoading.html#introduction">Introduction</a></li>
<li title="The Load Phases"><a href="CodeLoading.html#the-load-phases">The Load Phases</a></li>
<li title="The Finishing Sequence"><a href="CodeLoading.html#the-finishing-sequence">The Finishing Sequence</a></li>
</ul>
</li>
<li id="no" title="Non-blocking trace setting" expanded="false">Non-blocking trace setting<ul>
<li><a href="Tracing.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="Tracing.html#introduction">Introduction</a></li>
<li title="Redesign of Breakpoint Wheel"><a href="Tracing.html#redesign-of-breakpoint-wheel">Redesign of Breakpoint Wheel</a></li>
<li title="Same Same but Different"><a href="Tracing.html#same-same-but-different">Same Same but Different</a></li>
<li title="Adding a new Breakpoint"><a href="Tracing.html#adding-a-new-breakpoint">Adding a new Breakpoint</a></li>
<li title="To Updating and Remove Breakpoints"><a href="Tracing.html#to-updating-and-remove-breakpoints">To Updating and Remove Breakpoints</a></li>
<li title="Global Tracing"><a href="Tracing.html#global-tracing">Global Tracing</a></li>
<li title="Future work"><a href="Tracing.html#future-work">Future work</a></li>
</ul>
</li>
<li id="loadscrollpos" title="Delayed Dealloc" expanded="true">Delayed Dealloc<ul>
<li><a href="DelayedDealloc.html">
              Top of chapter
            </a></li>
<li title="Problem"><a href="DelayedDealloc.html#problem">Problem</a></li>
<li title="Functionality Used to Address This problem"><a href="DelayedDealloc.html#functionality-used-to-address-this-problem">Functionality Used to Address This problem</a></li>
</ul>
</li>
<li id="no" title="The beam_makeops script" expanded="false">The beam_makeops script<ul>
<li><a href="beam_makeops.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="beam_makeops.html#introduction">Introduction</a></li>
<li title="An example: the move instruction"><a href="beam_makeops.html#an-example--the-move-instruction">An example: the move instruction</a></li>
<li title="Short overview of instruction loading"><a href="beam_makeops.html#short-overview-of-instruction-loading">Short overview of instruction loading</a></li>
<li title="Running beam_makeops"><a href="beam_makeops.html#running-beam_makeops">Running beam_makeops</a></li>
<li title="Syntax of .tab files"><a href="beam_makeops.html#syntax-of-.tab-files">Syntax of .tab files</a></li>
</ul>
</li>
<li id="no" title="Counting Instructions" expanded="false">Counting Instructions<ul><li><a href="CountingInstructions.html">
              Top of chapter
            </a></li></ul>
</li>
<li id="no" title="Erlang Garbage Collector" expanded="false">Erlang Garbage Collector<ul>
<li><a href="GarbageCollection.html">
              Top of chapter
            </a></li>
<li title="Overview"><a href="GarbageCollection.html#overview">Overview</a></li>
<li title="Generational Garbage Collection"><a href="GarbageCollection.html#generational-garbage-collection">Generational Garbage Collection</a></li>
<li title="The young heap"><a href="GarbageCollection.html#the-young-heap">The young heap</a></li>
<li title="Sizing the heap"><a href="GarbageCollection.html#sizing-the-heap">Sizing the heap</a></li>
<li title="Literals"><a href="GarbageCollection.html#literals">Literals</a></li>
<li title="Binary heap"><a href="GarbageCollection.html#binary-heap">Binary heap</a></li>
<li title="Messages"><a href="GarbageCollection.html#messages">Messages</a></li>
<li title="References"><a href="GarbageCollection.html#references">References</a></li>
</ul>
</li>
<li id="no" title="Process and Port Tables" expanded="false">Process and Port Tables<ul>
<li><a href="PTables.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="PTables.html#problems">Problems</a></li>
<li title="Solution"><a href="PTables.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Port Signals" expanded="false">Port Signals<ul>
<li><a href="PortSignals.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="PortSignals.html#problems">Problems</a></li>
<li title="Solution"><a href="PortSignals.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Process Management Optimizations" expanded="false">Process Management Optimizations<ul>
<li><a href="ProcessManagementOptimizations.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="ProcessManagementOptimizations.html#problems">Problems</a></li>
<li title="Solution"><a href="ProcessManagementOptimizations.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Super Carrier" expanded="false">Super Carrier<ul>
<li><a href="SuperCarrier.html">
              Top of chapter
            </a></li>
<li title="Problem"><a href="SuperCarrier.html#problem">Problem</a></li>
<li title="Solution"><a href="SuperCarrier.html#solution">Solution</a></li>
</ul>
</li>
</ul>
</div></div>
<div id="content">
<div class="innertube">
<h1>5 Delayed Dealloc</h1>


<h3>
<a name="Problem"></a><span onMouseOver="document.getElementById('ghlink-problem-idm30095').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-problem-idm30095').style.visibility = 'hidden';"><a class="title_link" name="problem">5.1 
          Problem</a><span id="ghlink-problem-idm30095" class="ghlink-after"><a href="#problem" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h3>



<p>
An easy way to handle memory allocation in a multi-threaded
environment is to protect the memory allocator with a global lock
which threads performing memory allocations or deallocations have to
have locked during the whole operation. This solution of course scales
very poorly, due to heavy lock contention. An improved solution of
this scheme is to use multiple thread specific instances of such an
allocator. That is, each thread allocates in its own allocator
instance which is protected by a lock. In the general case references
to memory need to be passed between threads. In the case where a
thread that needs to deallocate memory that originates from another
threads allocator instance a lock conflict is possible. In a system as
the Erlang VM where memory allocation/deallocation is frequent and
references to memory also are passed around between threads this
solution will also scale poorly due to lock contention.
</p>



<h3>
<a name="Functionality-Used-to-Address-This-problem"></a><span onMouseOver="document.getElementById('ghlink-functionality-used-to-address-this-problem-idm30099').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-functionality-used-to-address-this-problem-idm30099').style.visibility = 'hidden';"><a class="title_link" name="functionality-used-to-address-this-problem">5.2 
          Functionality Used to Address This problem</a><span id="ghlink-functionality-used-to-address-this-problem-idm30099" class="ghlink-after"><a href="#functionality-used-to-address-this-problem" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h3>



<p>
In order to reduce contention due to locking of allocator instances we
introduced completely lock free instances tied to each scheduler
thread, and an extra locked instance for other threads. The scheduler
threads in the system is expected to do the major part of the
work. Other threads may still be needed but should not perform any
major and/or time critical work. The limited amount of contention that
appears on the locked allocator instance can more or less be
disregarded.
</p>

<p>
Since we still need to be able to pass references to memory between
scheduler threads we need some way to manage this. An allocator
instance belonging to one scheduler thread is only allowed to be
manipulated by that scheduler thread. When other threads need to
deallocate memory originating from a foreign allocator instance, they
only pass the memory block to a "message box" containing deallocation
jobs attached to the originating allocator instance. When a scheduler
thread detects such deallocation job it performs the actual
deallocation.
</p>

<p>
The "message box" is implemented using a lock free single linked list
through the memory blocks to deallocate. The order of the elements in
this list is not important. Insertion of new free blocks will be made
somewhere near the end of this list. Requiring that the new blocks
need to be inserted at the end would cause unnecessary contention when
large amount of memory blocks are inserted simultaneous by multiple
threads.
</p>

<p>
The data structure referring to this single linked list cover two cache
lines. One cache line containing information about the head of the
list, and one cache line containing information about the tail of the
list. This in order to reduce cache line ping ponging of this data
structure. The head of the list will only be manipulated by the thread
owning the allocator instance, and the tail will be manipulated by
other threads inserting deallocation jobs.
</p>

<h4>
<a name="Functionality-Used-to-Address-This-problem_Tail"></a><span onMouseOver="document.getElementById('ghlink-tail-idm30106').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-tail-idm30106').style.visibility = 'hidden';"><a class="title_link" name="tail">Tail</a><span id="ghlink-tail-idm30106" class="ghlink-after"><a href="#tail" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
In the tail part of the data structure we find a pointer to the last
element of the list, or at least something that is near the end of the
list. In the uncontended case it will point to the end of the list,
but when simultaneous insert operations are performed it will point to
something near the end of the list.
</p>

<p>
When inserting an element one will try to write a pointer to the new
element in the next pointer of the element pointed to by the last
pointer. This is done using an atomic compare and swap that expects
the next pointer to be <span class="code">NULL</span>. If this succeeds the thread performing
this operation moves the last pointer to point to the newly inserted
element.
</p>

<p>
If the atomic compare and swap described above failed, the last
pointer didn't point to the last element. In this case we need to
insert the new element somewhere between the element that the last
pointer pointed to and the actual last element. If we do it this way
the last pointer will eventually end up at the last element when
threads stop adding new elements. When trying to insert somewhere near
the end and failing to do so, the inserting thread sometimes moves to
the next element and sometimes tries with the same element again. This
in order to spread the inserted elements during heavy contention. That
is, we try to spread the modifications of memory to different
locations instead of letting all threads continue to try to modify the
same location in memory.
</p>



<h4>
<a name="Functionality-Used-to-Address-This-problem_Head"></a><span onMouseOver="document.getElementById('ghlink-head-idm30113').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-head-idm30113').style.visibility = 'hidden';"><a class="title_link" name="head">Head</a><span id="ghlink-head-idm30113" class="ghlink-after"><a href="#head" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
The head contains pointers to beginning of the list (<span class="code">head.first</span>), and
to the first block which other threads may refer to
(<span class="code">head.unref_end</span>). Blocks between these pointers are only refered to
by the head part of the data structure which is only used by the
thread owning the allocator instance. When these two pointers are not
equal the thread owning the allocator instance deallocate block after
block until <span class="code">head.first</span> reach <span class="code">head.unref_end</span>.
</p>

<p>
We of course periodically need to move the <span class="code">head.unref_end</span> closer to
the end in order to be able to continue deallocating memory
blocks. Since all threads inserting new elements in the linked list
will enter the list using the last pointer we can use this
knowledge. If we call <span class="code">erts_thr_progress_later()</span> and wait until we
have reached that thread progress we know that no managed threads can
refer the elements up to the element pointed to by the last pointer at
the time when we called <span class="code">erts_thr_progress_later()</span>. This since, all
managed threads must have left the code implementing this at least
once, and they always enters into the list via the last pointer. The
<span class="code">tail.next</span> field contains information about next <span class="code">head.unref_end</span>
pointer and thread progress that needs to be reached before we can
move <span class="code">head.unref_end</span>.
</p>

<p>
Unfortunately not only threads managed by the thread progress
functionality may insert memory blocks. Other threads also needs to be
taken care of. Other threads will not be as frequent users of this
functionality as managed threads, so using a less efficient scheme for
them is not that big of a problem. In order to handle unmanaged
threads we use two reference counters. When an unmanaged thread enters
this implementation it increments the reference counter currently
used, and when it leaves this implementation it decrements the same
reference counter. When the consumer thread calls
<span class="code">erts_thr_progress_later()</span> in order to determine when it is safe to
move <span class="code">head.unref_end</span>, it also swaps reference counters for unmanaged
threads. The previous current represents outstanding references from
the time up to this point. The new current represents future reference
following this point. When the consumer thread detects that we have
both reached the desired thread progress and when the previous current
reference counter reach zero it is safe to move the <span class="code">head.unref_end</span>.
</p>

<p>
The reason for using two reference counters is that we need to know
that the reference counter eventually will reach zero. If we only used
one reference counter it would potentially be held above zero for ever
by different unmanaged threads.
</p>



<h4>
<a name="Functionality-Used-to-Address-This-problem_Empty-List"></a><span onMouseOver="document.getElementById('ghlink-empty-list-idm30133').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-empty-list-idm30133').style.visibility = 'hidden';"><a class="title_link" name="empty-list">Empty List</a><span id="ghlink-empty-list-idm30133" class="ghlink-after"><a href="#empty-list" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
If no new memory blocks are inserted into the list, it should
eventually be emptied. All pointers to the list however expect to
always point to something. This is solved by inserting an empty
"marker" element, which only has to purpose of being there in the
absense of other elements. That is when the list is empty it only
contains this "marker" element.
</p>



<h4>
<a name="Functionality-Used-to-Address-This-problem_Contention"></a><span onMouseOver="document.getElementById('ghlink-contention-idm30137').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-contention-idm30137').style.visibility = 'hidden';"><a class="title_link" name="contention">Contention</a><span id="ghlink-contention-idm30137" class="ghlink-after"><a href="#contention" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
When elements are continuously inserted by threads not owning the
allocator instance, the thread owning the allocator instance will be
able to work more or less undisturbed by other threads at the head end
of the list. At the tail end large amounts of simultaneous inserts may
cause contention, but we reduce such contention by spreading inserts
of new elements near the end instead of requiring all new elements to
be inserted at the end.
</p>



<h4>
<a name="Functionality-Used-to-Address-This-problem_Schedulers-and-The-Locked-Allocator-Instance"></a><span onMouseOver="document.getElementById('ghlink-schedulers-and-the-locked-allocator-instance-idm30141').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-schedulers-and-the-locked-allocator-instance-idm30141').style.visibility = 'hidden';"><a class="title_link" name="schedulers-and-the-locked-allocator-instance">Schedulers and The Locked Allocator Instance</a><span id="ghlink-schedulers-and-the-locked-allocator-instance-idm30141" class="ghlink-after"><a href="#schedulers-and-the-locked-allocator-instance" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
Also the locked allocator instance for use by non-scheduler threads
have a message box for deallocation jobs just as all the other
allocator instances. The reason for this is that other threads may
allocate memory pass it to a scheduler that then needs to deallocate
it. We do not want the scheduler to have to wait for the lock on this
locked instance. Since also locked instances has message boxes for
deallocation jobs, the scheduler can just insert the job and avoid the
locking.
</p>



<h4>
<a name="Functionality-Used-to-Address-This-problem_A-Benchmark-Result"></a><span onMouseOver="document.getElementById('ghlink-a-benchmark-result-idm30145').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-a-benchmark-result-idm30145').style.visibility = 'hidden';"><a class="title_link" name="a-benchmark-result">A Benchmark Result</a><span id="ghlink-a-benchmark-result-idm30145" class="ghlink-after"><a href="#a-benchmark-result" title="Link to this place!"><span class="paperclip-after"></span></a></span></span>
</h4>



<p>
When running the ehb benchmark, large amount of messages are passed
around between schedulers. All message passing will in some way or the
other cause memory allocation and deallocation. Since messages are
passed between different schedulers we will get contention on the
allocator instances where messages were allocated. By the introduction
of the delayed dealloc feature, we got a speedup of between 25-45%,
depending on configuration of the benchmark, when running on a
relatively new machine with an Intel i7 quad core processor with
hyper-threading using 8 schedulers.</p>




</div>
<div class="footer">
<hr>
<p>Copyright © 1997-2024 Ericsson AB. All Rights Reserved.</p>
</div>
</div>
</div>
<script type="text/javascript">window.__otpTopDocDir = '../../js/';</script><script type="text/javascript" src="../../js/highlight.js"></script>
</body>
</html>
