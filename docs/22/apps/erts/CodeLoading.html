<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html xmlns:erl="http://erlang.org" xmlns:fn="http://www.w3.org/2005/02/xpath-functions">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../otp_doc.css" type="text/css">
<title>Erlang -- Non-Blocking Code Loading</title>
</head>
<body>
<div id="container">
<script id="js" type="text/javascript" language="JavaScript" src="../../js/flipmenu/flipmenu.js"></script><script id="js2" type="text/javascript" src="../../js/erlresolvelinks.js"></script><script language="JavaScript" type="text/javascript">
            <!--
              function getWinHeight() {
                var myHeight = 0;
                if( typeof( window.innerHeight ) == 'number' ) {
                  //Non-IE
                  myHeight = window.innerHeight;
                } else if( document.documentElement && ( document.documentElement.clientWidth ||
                                                         document.documentElement.clientHeight ) ) {
                  //IE 6+ in 'standards compliant mode'
                  myHeight = document.documentElement.clientHeight;
                } else if( document.body && ( document.body.clientWidth || document.body.clientHeight ) ) {
                  //IE 4 compatible
                  myHeight = document.body.clientHeight;
                }
                return myHeight;
              }

              function setscrollpos() {
                var objf=document.getElementById('loadscrollpos');
                 document.getElementById("leftnav").scrollTop = objf.offsetTop - getWinHeight()/2;
              }

              function addEvent(obj, evType, fn){
                if (obj.addEventListener){
                obj.addEventListener(evType, fn, true);
                return true;
              } else if (obj.attachEvent){
                var r = obj.attachEvent("on"+evType, fn);
                return r;
              } else {
                return false;
              }
             }

             addEvent(window, 'load', setscrollpos);

             //--></script><div id="leftnav"><div class="innertube">
<div class="erlang-logo-wrapper"><a href="../../index.html"><img alt="Erlang Logo" src="../../erlang-logo.png" class="erlang-logo"></a></div>
<p class="section-title">Erlang Run-Time System Application (ERTS)</p>
<p class="section-subtitle">Internal Documentation</p>
<p class="section-version">Version 10.7.2.14</p>
<ul class="panel-sections">
<li><a href="users_guide.html">User's Guide</a></li>
<li><a href="index.html">Reference Manual</a></li>
<li><a href="internal_docs.html">Internal Documentation</a></li>
<li><a href="release_notes.html">Release Notes</a></li>
<li><a href="erts.pdf">PDF</a></li>
<li><a href="../../index.html">Top</a></li>
</ul>
<ul class="expand-collapse-items">
<li><a href="javascript:openAllFlips()">Expand All</a></li>
<li><a href="javascript:closeAllFlips()">Contract All</a></li>
</ul>
<h3>Chapters</h3>
<ul class="flipMenu" imagePath="../../js/flipmenu">
<li id="no" title="Carrier Migration" expanded="false">Carrier Migration<ul>
<li><a href="CarrierMigration.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="CarrierMigration.html#introduction">Introduction</a></li>
<li title="Problem"><a href="CarrierMigration.html#problem">Problem</a></li>
<li title="Solution"><a href="CarrierMigration.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Thread Progress" expanded="false">Thread Progress<ul>
<li><a href="ThreadProgress.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="ThreadProgress.html#problems">Problems</a></li>
<li title="Functionality Used to Address These Problems"><a href="ThreadProgress.html#functionality-used-to-address-these-problems">Functionality Used to Address These Problems</a></li>
<li title="Implementation of the Thread Progress Functionality"><a href="ThreadProgress.html#implementation-of-the-thread-progress-functionality">Implementation of the Thread Progress Functionality</a></li>
</ul>
</li>
<li id="loadscrollpos" title="Non-Blocking Code Loading" expanded="true">Non-Blocking Code Loading<ul>
<li><a href="CodeLoading.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="CodeLoading.html#introduction">Introduction</a></li>
<li title="The Load Phases"><a href="CodeLoading.html#the-load-phases">The Load Phases</a></li>
<li title="The Finishing Sequence"><a href="CodeLoading.html#the-finishing-sequence">The Finishing Sequence</a></li>
</ul>
</li>
<li id="no" title="Non-blocking trace setting" expanded="false">Non-blocking trace setting<ul>
<li><a href="Tracing.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="Tracing.html#introduction">Introduction</a></li>
<li title="Redesign of Breakpoint Wheel"><a href="Tracing.html#redesign-of-breakpoint-wheel">Redesign of Breakpoint Wheel</a></li>
<li title="Same Same but Different"><a href="Tracing.html#same-same-but-different">Same Same but Different</a></li>
<li title="Adding a new Breakpoint"><a href="Tracing.html#adding-a-new-breakpoint">Adding a new Breakpoint</a></li>
<li title="To Updating and Remove Breakpoints"><a href="Tracing.html#to-updating-and-remove-breakpoints">To Updating and Remove Breakpoints</a></li>
<li title="Global Tracing"><a href="Tracing.html#global-tracing">Global Tracing</a></li>
<li title="Future work"><a href="Tracing.html#future-work">Future work</a></li>
</ul>
</li>
<li id="no" title="Delayed Dealloc" expanded="false">Delayed Dealloc<ul>
<li><a href="DelayedDealloc.html">
              Top of chapter
            </a></li>
<li title="Problem"><a href="DelayedDealloc.html#problem">Problem</a></li>
<li title="Functionality Used to Address This problem"><a href="DelayedDealloc.html#functionality-used-to-address-this-problem">Functionality Used to Address This problem</a></li>
</ul>
</li>
<li id="no" title="The beam_makeops script" expanded="false">The beam_makeops script<ul>
<li><a href="beam_makeops.html">
              Top of chapter
            </a></li>
<li title="Introduction"><a href="beam_makeops.html#introduction">Introduction</a></li>
<li title="An example: the move instruction"><a href="beam_makeops.html#an-example--the-move-instruction">An example: the move instruction</a></li>
<li title="Short overview of instruction loading"><a href="beam_makeops.html#short-overview-of-instruction-loading">Short overview of instruction loading</a></li>
<li title="Running beam_makeops"><a href="beam_makeops.html#running-beam_makeops">Running beam_makeops</a></li>
<li title="Syntax of .tab files"><a href="beam_makeops.html#syntax-of-.tab-files">Syntax of .tab files</a></li>
</ul>
</li>
<li id="no" title="Counting Instructions" expanded="false">Counting Instructions<ul><li><a href="CountingInstructions.html">
              Top of chapter
            </a></li></ul>
</li>
<li id="no" title="Erlang Garbage Collector" expanded="false">Erlang Garbage Collector<ul>
<li><a href="GarbageCollection.html">
              Top of chapter
            </a></li>
<li title="Overview"><a href="GarbageCollection.html#overview">Overview</a></li>
<li title="Generational Garbage Collection"><a href="GarbageCollection.html#generational-garbage-collection">Generational Garbage Collection</a></li>
<li title="The young heap"><a href="GarbageCollection.html#the-young-heap">The young heap</a></li>
<li title="Sizing the heap"><a href="GarbageCollection.html#sizing-the-heap">Sizing the heap</a></li>
<li title="Literals"><a href="GarbageCollection.html#literals">Literals</a></li>
<li title="Binary heap"><a href="GarbageCollection.html#binary-heap">Binary heap</a></li>
<li title="Messages"><a href="GarbageCollection.html#messages">Messages</a></li>
<li title="References"><a href="GarbageCollection.html#references">References</a></li>
</ul>
</li>
<li id="no" title="Process and Port Tables" expanded="false">Process and Port Tables<ul>
<li><a href="PTables.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="PTables.html#problems">Problems</a></li>
<li title="Solution"><a href="PTables.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Port Signals" expanded="false">Port Signals<ul>
<li><a href="PortSignals.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="PortSignals.html#problems">Problems</a></li>
<li title="Solution"><a href="PortSignals.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Process Management Optimizations" expanded="false">Process Management Optimizations<ul>
<li><a href="ProcessManagementOptimizations.html">
              Top of chapter
            </a></li>
<li title="Problems"><a href="ProcessManagementOptimizations.html#problems">Problems</a></li>
<li title="Solution"><a href="ProcessManagementOptimizations.html#solution">Solution</a></li>
</ul>
</li>
<li id="no" title="Super Carrier" expanded="false">Super Carrier<ul>
<li><a href="SuperCarrier.html">
              Top of chapter
            </a></li>
<li title="Problem"><a href="SuperCarrier.html#problem">Problem</a></li>
<li title="Solution"><a href="SuperCarrier.html#solution">Solution</a></li>
</ul>
</li>
</ul>
</div></div>
<div id="content">
<div class="innertube">
<h1>3 Non-Blocking Code Loading</h1>


<h3>
<a name="Introduction"></a><span onMouseOver="document.getElementById('ghlink-introduction-idm30155').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-introduction-idm30155').style.visibility = 'hidden';"><span id="ghlink-introduction-idm30155"></span><a class="title_link" name="introduction" href="#introduction">3.1 
          Introduction</a></span>
</h3>



<p>
Before OTP R16 when an Erlang code module was loaded, all other
execution in the VM were halted while the load operation was carried
out in single threaded mode. This might not be a big problem for
initial loading of modules during VM boot, but it can be a severe
problem for availability when upgrading modules or adding new code on
a VM with running payload. This problem grows with the number of cores
as both the time it takes to wait for all schedulers to stop increases
as well as the potential amount of halted ongoing work.
</p>

<p>
In OTP R16, modules are loaded without blocking the VM.
Erlang processes may continue executing undisturbed in parallel during
the entire load operation. The code loading is carried out by a normal
Erlang process that is scheduled like all the others. The load
operation is completed by making the loaded code visible to all
processes in a consistent way with one single atomic
instruction. Non-blocking code loading will improve real-time
characteristics when modules are loaded/upgraded on a running SMP
system.
</p>



<h3>
<a name="The-Load-Phases"></a><span onMouseOver="document.getElementById('ghlink-the-load-phases-idm30160').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-the-load-phases-idm30160').style.visibility = 'hidden';"><span id="ghlink-the-load-phases-idm30160"></span><a class="title_link" name="the-load-phases" href="#the-load-phases">3.2 
          The Load Phases</a></span>
</h3>



<p>
The loading of a module is divided into two phases; a <strong>prepare phase</strong>
and a <strong>finishing phase</strong>. The prepare phase contains reading the BEAM
file format and all the preparations of the loaded code that can
easily be done without interference with the running code. The
finishing phase will make the loaded (and prepared) code accessible
from the running code. Old module versions (replaced or deleted) will
also be made inaccessible by the finishing phase.
</p>

<p>
The prepare phase is designed to allow several "loader" processes to
prepare separate modules in parallel while the finishing phase can
only be done by one loader process at a time. A second loader process
trying to enter finishing phase will be suspended until the first
loader is done. This will only block the process, the scheduler is
free to schedule other work while the second loader is waiting. (See
<span class="code">erts_try_seize_code_write_permission</span> and
<span class="code">erts_release_code_write_permission</span>).
</p>

<p>
The ability to prepare several modules in parallel is not currently
used as almost all code loading is serialized by the code_server
process. The BIF interface is however prepared for this.
</p>

<div class="example example-none"><pre>  erlang:prepare_loading(Module, Code) -&gt; LoaderState
  erlang:finish_loading([LoaderState])</pre></div>
<p>
The idea is that <span class="code">prepare_loading</span> could be called in parallel for
different modules and returns a "magic binary" containing the internal
state of each prepared module. Function <span class="code">finish_loading</span> could take a
list of such states and do the finishing of all of them in one go.
</p>

<p>
Currenlty we use the legacy BIF <span class="code">erlang:load_module</span> which is now
implemented in Erlang by calling the above two functions in
sequence. Function <span class="code">finish_loading</span> is limited to only accepts a list
with one module state as we do not yet use the multi module loading
feature.
</p>



<h3>
<a name="The-Finishing-Sequence"></a><span onMouseOver="document.getElementById('ghlink-the-finishing-sequence-idm30177').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-the-finishing-sequence-idm30177').style.visibility = 'hidden';"><span id="ghlink-the-finishing-sequence-idm30177"></span><a class="title_link" name="the-finishing-sequence" href="#the-finishing-sequence">3.3 
          The Finishing Sequence</a></span>
</h3>



<p>
During VM execution, code is accessed through a number of data
structures. These <strong>code access structures</strong> are
</p>

<ul>
<li>
Export table. One entry for every exported function.

</li>
<li>
Module table. One entry for each loaded module.

</li>
<li>
"beam_catches". Identifies jump destinations for catch instructions.

</li>
<li>
"beam_ranges". Map code address to function and line in source file.

</li>
</ul>
<p>
The most frequently used of these structures is the export table that
is accessed in run time for every executed external function call to
get the address of the callee. For performance reasons, we want to
access all these structures without any overhead from thread
synchronization. Earlier this was solved with an emergency break. Stop
the entire VM to mutate these code access structures, otherwise treat
them as read-only.
</p>

<p>
The solution in R16 is instead to <strong>replicate</strong> the code access
structures. We have one set of active structures read by the running
code. When new code is loaded the active structures are copied, the
copy is updated to include the newly loaded module and then a switch
is made to make the updated copy the new active set. The active set is
identified by a single global atomic variable
<span class="code">the_active_code_index</span>. The switch can thus be made by a single
atomic write operation. The running code have to read this atomic
variable when using the active access structures, which means one
atomic read operation per external function call for example. The
performance penalty from this extra atomic read is however very small
as it can be done without any memory barriers at all (as described
below). With this solution we also preserve the transactional feature
of a load operation. Running code will never see the intermediate
result of a half loaded module.
</p>

<p>
The finishing phase is carried out in the following sequence by the
BIF <span class="code">erlang:finish_loading</span>:
</p>

<ul>
<li>
<p>Seize exclusive code write permission (suspend process if needed
until we get it).
</p>

</li>
<li>
<p>Make a full copy of all the active access structures. This copy is
called the staging area and is identified by the global atomic
variable <span class="code">the_staging_code_index</span>.
</p>

</li>
<li>
<p>Update all access structures in the staging area to include the
newly prepared module.
</p>

</li>
<li>
<p>Schedule a thread progress event. That is a time in the future when
all schedulers have yielded and executed a full memory barrier.
</p>

</li>
<li>
<p>Suspend the loader process.
</p>

</li>
<li>
<p>After thread progress, commit the staging area by assigning
<span class="code">the_staging_code_index</span> to <span class="code">the_active_code_index</span>.
</p>

</li>
<li>
<p>Release the code write permission allowing other processes to stage
new code.
</p>

</li>
<li>
<p>Resume the loader process allowing it to return from
<span class="code">erlang:finish_loading</span>.
</p>
</li>
</ul>
<h4>
<a name="The-Finishing-Sequence_Thread-Progress"></a><span onMouseOver="document.getElementById('ghlink-thread-progress-idm30214').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-thread-progress-idm30214').style.visibility = 'hidden';"><span id="ghlink-thread-progress-idm30214"></span><a class="title_link" name="thread-progress" href="#thread-progress">Thread Progress</a></span>
</h4>



<p>
The waiting for thread progress in 4-6 is necessary in order for
processes to read <span class="code">the_active_code_index</span> atomic during normal
execution without any expensive memory barriers. When we write a new
value into <span class="code">the_active_code_index</span> in step 6, we know that all
schedulers will see an updated and consistent view of all the new
active access structures once they become reachable through
<span class="code">the_active_code_index</span>.
</p>

<p>
The total lack of memory barrier when reading <span class="code">the_active_code_index</span>
has one interesting consequence however. Different processes may see
the new code at different point in time depending on when different
cores happen to refresh their hardware caches. This may sound unsafe
but it actually does not matter. The only property we must guarantee
is that the ability to see the new code must spread with process
communication. After receiving a message that was triggered by new
code, the receiver must be guaranteed to also see the new code. This
will be guaranteed as all types of process communication involves
memory barriers in order for the receiver to be sure to read what the
sender has written. This implicit memory barrier will then also make
sure that the receiver reads the new value of <span class="code">the_active_code_index</span>
and thereby also sees the new code. This is true for all kinds of
inter process communication (TCP, ETS, process name registering,
tracing, drivers, NIFs, etc) not just Erlang messages.
</p>



<h4>
<a name="The-Finishing-Sequence_Code-Index-Reuse"></a><span onMouseOver="document.getElementById('ghlink-code-index-reuse-idm30224').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-code-index-reuse-idm30224').style.visibility = 'hidden';"><span id="ghlink-code-index-reuse-idm30224"></span><a class="title_link" name="code-index-reuse" href="#code-index-reuse">Code Index Reuse</a></span>
</h4>



<p>
To optimize the copy operation in step 2, code access structures are
reused. In current solution we have three sets of code access
structures, identified by a code index of 0, 1 and 2. These indexes
are used in a round robin fashion. Instead of having to initialize a
completely new copy of all access structures for every load operation
we just have to update with the changes that have happened since the
last two code load operations. We could get by with only two code
indexes (0 and 1), but that would require yet another round of waiting
for thread progress before step 2 in the <span class="code">finish_loading</span> sequence. We
cannot start reusing a code index as staging area until we know that
no lingering scheduler thread is still using it as the active code
index. With three generations of code indexes, the waiting for thread
progress in step 4-6 will give this guarantee for us. Thread progress
will wait for all running schedulers to reschedule at least one
time. No ongoing execution reading code access structures reached from
an old value of <span class="code">the_active_code_index</span> can exist after a second round
of thread progress.
</p>

<p>
The design choice between two or three generations of code access
structures is a trade-off between memory consumption and code loading
latency.
</p>



<h4>
<a name="The-Finishing-Sequence_A-Consistent-Code-View"></a><span onMouseOver="document.getElementById('ghlink-a-consistent-code-view-idm30231').style.visibility = 'visible';" onMouseOut="document.getElementById('ghlink-a-consistent-code-view-idm30231').style.visibility = 'hidden';"><span id="ghlink-a-consistent-code-view-idm30231"></span><a class="title_link" name="a-consistent-code-view" href="#a-consistent-code-view">A Consistent Code View</a></span>
</h4>



<p>
Some native BIFs may need to get a consistent snapshot view of the
active code. To do this it is important to only read
<span class="code">the_active_code_index</span> one time and then use that index value for all
code accessing during the BIF. If a load operation is executed in
parallel, reading <span class="code">the_active_code_index</span> a second time might result
in a different value, and thereby a different view of the code.
</p>




</div>
<div class="footer">
<hr>
<p>Copyright © 1997-2021 Ericsson AB. All Rights Reserved.</p>
</div>
</div>
</div>
<script type="text/javascript">window.__otpTopDocDir = '../../js/';</script><script type="text/javascript" src="../../js/highlight.js"></script>
</body>
</html>
